# 05_1. Logistic Regression

- 분류 기법 중 하나임
- 도형 분류에 많이 사용되는 알고리즘
- 모델이 만들어지는 원리 이해가 중요

## 목차

- What is Logistic Regression?
  - Classification
  - Logistic vs Linear
- How to solve?
  - Hypothesis Representation
  - Sigmoid/Logistic Function
  - Decision Boundary
  - Cost Function
  - Optimizer (Gradient Descent)
- Codes(Eager Execution)
- Summary

## Classification

- 어떤 게 Binary(Multi-class) Classification?
  - 변수가 0이거나 1이다(0: positive / 1:negative)
- 시험: Pass or Fail
- 스팸:스팸이 아니다(정상) 또는 스팸
- 얼굴: 진짜 또는 사기
- Tumor

 머신러닝 하기 위해서는 0,1 Binary Classficiation 위한 두 가지 값으로 나뉘어야 함

```python
x_train = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 4]]
y_train = [[0], [0], [0], [1], [1], [1]]
```

이런 것들을 통해 Logistic Regression 만들 수 있음

## Logistic vs Linear

- Logistic
  - ![](pic\LRg.PNG)
  - 두 가지의 케이스를 구분선으로 구분 가능
  - 셀 수 있고 데이터가 흩어져 있음
  - ex) 신발 사이즈 등 (데이터가 구분이 됨)
- Linear
  - ![](pic\lR.PNG)
  - 데이터가 연속적임
  - 이어지는 데이터를 예측 가능함
  - ex) 시간, 몸무게, 키(연속적인 데이터)

```python
Logistic_Y = [[0], [0], [0], [1], [1], [1]] # One Hot
Linear_Y = [828.659973, 833.450012, 819.23999, 828.349976, 831.659973] # Numeric
```

### Hypothesis Representation

- 공부 많이 할 수록 합격률 높아짐
  - ![](\pic\hp.PNG)
  - Linear Regression 적용 경우 h(x) = WX
  - 그러나 연속적인 값이 아니라 0과 1로 구분해야 하므로 새로운 함수가 필요함

### Signmoid (Logistic) function

- g(z) function out value is between 0 and 1
- ![](pic\gzfunc.PNG)

- ![](pic\proc.PNG)

- z가 무한대에 가까울수록 함숫값이 1에 가까워지고, z가 마이너스 무한대에 가까울수록 함숫값이 0에 가까워진다. 

- ```python 
  [Tensorflow Code]
  hypothesis = tf.sigmoid(z)
  hypothesis = tf.div(1., 1 + tf.exp(z))
  ```

## Decision Boundary

**Linear / Non-linear decision boundary**

![](pic\db_1.PNG)

![](\pic\db_2.PNG)

```python
[Tensorflow Code]
predicted = tf.cast(hypothesis > 0.5, dtype=tf.int32)
```

## Cost Function

최적의 파라미터로 만드는 게 cost function

