# Chapter3. 딥러닝 기초

## 3.1 딥러닝 개요

- 다수의 층으로 구성된 신경망을 사용하는 머신러닝의 한 방법
- '뉴런'이라는 개별 단위로 구성됨
- 각 입력마다 C = W*x + b를 만족시킴
  - W: 가중치
  - x: 입력값
  - b: bias, 편향
  - C를 활성화 함수 통해 처리하면 출력이 됨
  - 이런 뉴런들을 여러 층을 만들고 연결하면 신경망이 구축됨
  - 신경망 전체에 입출력 존재, 출력과 정답과의 오차가 줄어들드록 파라미터 조정하면서 학습이 진행
- **역전파**(오차 역전파): 1개 층씩 반대 방향으로 오차 전파 -> 가중치와 편향 수정
  - 신경망의 여러 파라미터가 반복적으로 조정되면서 네트워크는 조금씩 학습, 적절한 예측 가능해짐
  - 여러 층으로 구성된 신경망의 학습 = 딥러닝(심층학습)

### 3.1.2 층의 방향과 층의 개수

- 은닉층: 입력층과 출력층 사이에 위치한 여러 개의 층

- 순전파: 입력 -> 출력 방향으로 정보 전달
- 역전파: 출력 -> 입력 방향으로 정보 전달

### 3.1.3 경사 하강법

- 오차의 그래프가 있음
- 오차 E 를 가중치 w로 편미분한 값은 기울기인데 기울기가 최소가 되는 지점을 찾아야 함
- 실제로는 곡선의 형태를 알기 어려우니까 오차가 최소가 되는 방향으로 조금씩 가중치를 변화시킴
- 오차의 기울기가 조금씩 하강하도록 가중치 조금씩 줄여가면서 Global minimum을 찾는다.
- **확률적 경사 하강법**은 편미분 이용함

### 3.1.4 에포크와 배치 

- **에포크**: 모든 훈련 데이터를 1회 학습하는 것

- 샘플: 입력값, 정답값 한 쌍
- **배치**: 샘플 그룹
  - 1회 학습에 1개 배치가 사용됨
- **배치 사이즈**: 배치에 포함된 샘플 데이터의 개수
- **미니 배치**: 훈련 데이터를 작은 크기의 배치로 분할, 배치마다 학습시키는 것
- 배치 사이즈가 학습 시간과 성능에 영향을 줌

## 3.2 전결합층 순전파

