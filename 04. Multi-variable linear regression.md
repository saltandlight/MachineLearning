#  04. Multi-variable linear regression

- 다변수 선형 회귀
- 시험점수 예측 시 변수가 3개 이상인 경우(Multi-variable or Multi-feature)

## Hypothesis

- H(x) = Wx + b

- H(x1, x2, x3) = w1x1 + w2x2 + w3x3

## Cost function

- H(x1, x2, x3) = w1x1 + w2x2 + w3x3
- ![](pic\cf_1.PNG)

## Multi-variable

- H(x1, x2, x3, ..., xn) = w1x1 + w2x2 + w3x3 + ... + wnxn + b

## Matrix

- 변수가 많아지면 일일이 다 기록이 힘듬
- 행렬곱을 활용하여 표현하는 것이 좋다

### Hypothesis using matrix

- w1x1 + w2x2 + w3x3 + ... + wnxn
- ![](pic\hum1.PNG)

- H(X) = XW
  - 매트릭스 곱셈순서로 인해 이렇게 표기
- 앞의 매트릭스 열 갯수 = 뒤 매트릭스 행 갯수 여야 곱셈 가능
- [n, 3]  * [3, 1] => [n, 1]
- [n, 3] * [?, ?] => [n, 2]
  - 3, 2여야 함

#### Many x instances

- 데이터 건수가 어떠하든 동일하게 행렬로 표현 가능
- H(X) = XW

### WX vs XW

- lecture(이론상)
  - H(x) = Wx + b
  - 다른 곳에서는 W를 세타로 표현하기도 함(그러나 의미는 같다)
- Implementation(TensorFlow)
  - H(X) = XW