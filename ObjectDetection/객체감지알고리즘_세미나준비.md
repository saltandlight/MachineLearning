# Object Detection Algorithm

## 대략적인 흐름

- 객체 감지
- 객체 감지 알고리즘의 종류와 구성, 매커니즘

## 객체 감지(Object Detection) 소개

- 이미지 분류: 이미지에 클래스 label 할당

- 객체 위치 지정: 이미지의 하나 이상의 객체 주위에 bounding box 그리는 것 포함

- 이미지 분류 + 객체 위치 지정

   => 바운딩 박스 그리고 물체 구분해주는 라벨 할당

- 얘네들을 다 객체 인식이라고 함

- R-CNNs가 등장한 이유: 객체 Localization과 인식 과제 해결하기 위한 기법
- YOLO(You Look Only Once) 는 속도 및 실시간 사용 위해 설계된 객체 인식 위한 두 번째 기술 제품군

## Object Recognition 이란?

- 사진에서 물체 식별 포함하는 관련 컴퓨터 비전 작업 설명하는 일반적인 용어
- 이미지 분류: 이미지에서 한 개체의 클래스 예측하는 것 포함
- Object Localization: 1개 이상의 객체의 상황 파악 -> 그 범위 주위에 bounding box 그리는 것
- Object Detection이나 Object Recognition이나 혼용하여 쓰임
- 이렇게 구분할 수 있음
  - Image Classification(이미지 분류): 이미지에서 개체의 유형 또는 클래스 예측
    - input: 사진과 같이 하나의 물체가 있는 이미지(왜 하나? -> 하나여야 구분이 가능하니까?)
    - output: 클래스 label 
  - Object Localization: 이미지에서 개체 찾고 경계 상자 사용해서 위치 표시(지금 하고 있는 작업과 유사)
    - input: 하나 이상의 개체가 있는 이미지
    - output: 하나 이상의 bounding box
  - Object Detection: bounding box 내에서 객체의 존재 여부 및 이미지에서 찾은 객체의 클래스 유형 찾아라
    - input: 하나 이상의 개체가 있는 이미지 
    - output: 하나 이상의 bounding box 및 각 bounding box의 클래스 label
- 객체 분할(Object Segmentation): 현재 분류에 대한 추가적인 확장
  - Object Instance Segmentation이나 semantic segmentation이라고 불림
  - 바운딩 박스 대신에 객체의 특정 픽셀이 강조되도록 함
- Single-object Localization이 Object Localization의 단순한 버전
  - Localization 작업은 이미지 내에서 하나의 유형의 객체로 제한됨
  - 이게 더 쉬운 작업
  - 영상 분류 위한 모델 성능은 예측된 클래스 라벨의 평균 분류 오류 사용하여 평가됨
  - Singlie Object Localization 모델의 성능은 예상 클래스에 대한 예상 bounding box 및 예측 bounding box 사이의 거리를 사용하여 평가함
  - <-> Object Detection Model의 성능은 영상에서 알려진 객체에 대해 가장 잘 일치하는 bounding box 각각에 걸쳐 정밀도와 리콜을 사용하여 평가됨

### R-CNN 모델 패밀리

- R-CNN은 물체의 Localization, 감지, 분할 문제에 있어서 크고 성공적인 CNN 중에 첫번째 부분이었다.  
- 세 가지 모델로 구성되어 있음
  - 모듈 1: bounding box를 생성하고 추출
  - 모듈 2: Feature Extractor
    - ex) deep CNN을 사용하여 각 후보 지역에서 Feature  추출
  - 모듈 3:  Feature를 알려진 클래스 중 하나로 분류
    - ex) Linear SVM classifier model
- 컴퓨터 비전 기법은 'selective search'라고 불리는 이미지 내에서 잠재적인 물체의 bounding box를 제안하기 위해 사용됨 그러나, 다른 region proposal algorithm 사용 가능
- 물체 Localization과 recognition 문제에 CNN을 비교적 단순하고 쉽게 적용
  - A downside of the approach is that it’s slow, requiring a CNN-based feature extraction expire each of the candidate regions generated by the region proposal algorithm.
  - 접근방식의 단점: 느림. CNN 기반의 feature 추출이 regional proposal algorithm에 의해 생성된 후보 지역들을 만료시킴(후보 영역들을 다 돌기 때문에 느리다~ 이런 뜻인 듯)

### Faster R-CNN: (나중에 다시 보기)

- 이게 나온 이유:
  - selective search를 cpu에서 동작함
    - 네트워크에서 병목 현상이 발생 
    - => 후보 영역 추출 작업 수행하는 네트워크인 Regional Proposal Network(RPN) 도입 
- RPN + Fast R-CNN 모델

- MS Research에서 R-CNN의 속도 문제를 다루기 위한 확장판을 R-CNN의 2015년 논문에서 제안
- R-CNN의 한계에 대한 검토로 시작
  - 훈련은 다단계 파이프라인이다. 세 가지 다른 모델의 준비와 운영 포함
  - 훈련은 시공간적으로 비용이 많이 듬. 이미지당 엄청 많은 지역 제안에 대해 CNN을 깊이 훈련시키는 것은 매우 느림
  - 물체 감지 속도가 느림. 많은 지역 제안에 대해 CNN을 사용하여 예측하는 것은 매우 느림
- Faster R-CNN은 지역과 분류 직접 학습하고 출력하는 파이프라인X, 단일 모델로 제안됨
- 모델의 구조는 지역 제안들(regional proposal)의 사진을 찍는다.
  - 지역 제안들: deep cnn 에 의해 통과됨
- 1.  전체 이미지를 미리 학습된 CNN(ex. VGG-16)에 통과시켜서 feature map 추출
  2. feature map에서 RoI(Region of Interest)를 찾아줌
     - RoI들은 input 이미지에서 Selective Search 통해 찾은 것을 feature map에 적용
       - Selective Search 방식: 이미지 후보 영역 추천 시 사용하는 알고리즘
         - 자세한 것:https://go-hard.tistory.com/33
  3. 찾은 각각의 RoI에 대해 RoI Pooling을 진행 -> 고정된 크기의 벡터 추출
  4. feature vector 는 fully vector들을 통과한 후, softmax와 bounding box regression의 input으로 들어감
     - softmax는 SVM 대신하는 방법, 해당 RoI가 어떤 물체인지를 classification함
     - bounding box regression은 selective search로 찾은 박스 위치 조절
       - 여기서는 bounding box 말고 Anchor box 사용한다는 말이 있음
       - bounding box(크기가 일정), Anchor box(객체의 크기에 따라 유동)
- CNN은 ROI polling(Region of internest polling layer)

## Yolo Model Family

- YOLO = You Only Look Once
- R-CNN 보다 훨씬 빠르고 실시간으로 물체 감지 가능
- 모델 접근 방식은 단일 신경망 end-to-end 포함
  - 단일 신경망 end-to-end: 입력으로 사진 만들고 각 경계박스에 대한 박스, 클래스 라벨을 직접 예측함
  - 뭔소린지 모르겠다.
- 모델은 입력 이미지를 셀 격자로 분할해서 작동
  - 각 셀은 bounding box의 center가 셀 안에 있을 경우 bounding box 예측이 쉽다
  - 각 그리드셀은 x, y좌표, 폭, 높이 및 신뢰도 포함하는 bounding box 를 예측함
  - 클래스 예측은 각 셀에서 추가로 지원됨 
  - (Bounding boxes + confidence) & (Class probability map) => Final detections

### YOLO v2, YOLO v3

- 모델 성능 더 향상시키기 위해 업뎃
- Fast R-CNN 과 마찬가지로 YOLO v2 모델도 훈련 중 맞춤화된 유용한 모양과 크기의 앵커박스, 사전에 정의된 bounding box 사용함
- 이미지의 bounding box 선택은 교육 데이터 집합에 대한 k-평균 분석 사용하여 사전 처리됨
- YOLO v2: left top 꼭지점으로부터 얼만큼 이동하는 지를 예측함
- 위치, 크기를 직접 예측하기보다 cell에 비례하여 미리 정의된 앵커 박스를 이동, 재구성, 로지스틱 함수에 의해 추측되는 offset이 예측됨(이게 도대체 뭔 소리야;;)

https://saitejaamicable.medium.com/introduction-to-object-detection-algorithms-3b5c8580e6

https://herbwood.tistory.com/10

